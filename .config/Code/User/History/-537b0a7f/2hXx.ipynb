{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "from transformers import RobertaTokenizer, RobertaModel, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv(\"vaalit_2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2437 entries, 0 to 2436\n",
      "Columns: 212 entries, vaalipiiri to Lappi. Jäämeren rata pitää rakentaa..1\n",
      "dtypes: float64(5), int64(1), object(206)\n",
      "memory usage: 3.9+ MB\n",
      "None\n",
      "['Lappi. Lappiin ei saa avata yhtään uutta kaivosta ennen kuin yhtiöiltä aletaan periä kaivosveroa.', 'Lappi. Mahdollisen uuden maakuntahallinnon toimintoja ja työpaikkoja on sijoitettava muuallekin kuin Rovaniemelle.', 'Lappi. Lapin erikoissairaanhoito on keskitettävä kokonaan Rovaniemelle Lapin keskussairaalaan.', 'Lappi. Alkuperäiskansojen oikeuksia koskeva ILO-sopimus pitää ratifioida seuraavalla hallituskaudella. ', 'Lappi. Jäämeren rata pitää rakentaa.', 'Lappi. Lappiin ei saa avata yhtään uutta kaivosta ennen kuin yhtiöiltä aletaan periä kaivosveroa..1', 'Lappi. Mahdollisen uuden maakuntahallinnon toimintoja ja työpaikkoja on sijoitettava muuallekin kuin Rovaniemelle..1', 'Lappi. Lapin erikoissairaanhoito on keskitettävä kokonaan Rovaniemelle Lapin keskussairaalaan..1', 'Lappi. Alkuperäiskansojen oikeuksia koskeva ILO-sopimus pitää ratifioida seuraavalla hallituskaudella. .1', 'Lappi. Jäämeren rata pitää rakentaa..1'] 10\n"
     ]
    }
   ],
   "source": [
    "print(all_data.info())\n",
    "\n",
    "# Look at lappi related columns\n",
    "lappi_columns = [col for col in all_data.columns if col[:6] == 'Lappi.']\n",
    "print(lappi_columns, len(lappi_columns))\n",
    "\n",
    "# Print answers to a lappi question. We'll use these to test the encoder.\n",
    "lappi_question_idx = -1\n",
    "lappi_data = all_data[lappi_columns[lappi_question_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nykyinen ratasuunnitelma on todettu tutkimuksissa nykytilanteessa kannattamattomaksi. Lisäksi hanke aiheuttaa ongelmia ympäristölle ja alueen väestölle. Suunnitelmassa on kuitenkin yksi mielenkiintoinen osa. Junaradan jatkaminen Kemijärveltä Pyhätunturin kautta Sodankylään voisi olla toteuttamiskelpoinen ajatus.\\n\\nRatayhteys Jäämerelle voidaan saada aikaan toisella tavalla varsin helposti ja selvästi halvemmalla. Päivitetään nykyinen  Laurila-Tornio-Haaparanta ratayhteys. Tämän päivityksen hinta on vain murto-osa nyt suunnitellusta linjauksesta ja sillä saavutettaisiin ratayhteys Jäämeren ja Atlantin lisäksi myös keskeiseen Eurooppaan ja vaikka Välimerelle saakka. '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lappi_data.iloc[2432]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nykyinen ratasuunnitelma on todettu tutkimuksissa nykytilanteessa kannattamattomaksi. Lisäksi hanke aiheuttaa ongelmia ympäristölle ja alueen väestölle. Suunnitelmassa on kuitenkin yksi mielenkiintoinen osa. Junaradan jatkaminen Kemijärveltä Pyhätunturin kautta Sodankylään voisi olla toteuttamiskelpoinen ajatus.\n",
      "\n",
      "Ratayhteys Jäämerelle voidaan saada aikaan toisella tavalla varsin helposti ja selvästi halvemmalla. Päivitetään nykyinen  Laurila-Tornio-Haaparanta ratayhteys. Tämän päivityksen hinta on vain murto-osa nyt suunnitellusta linjauksesta ja sillä saavutettaisiin ratayhteys Jäämeren ja Atlantin lisäksi myös keskeiseen Eurooppaan ja vaikka Välimerelle saakka. \n"
     ]
    }
   ],
   "source": [
    "print(lappi_data.iloc[2432])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 509/509 [00:00<00:00, 667kB/s]\n",
      "Downloading: 100%|██████████| 1.33G/1.33G [01:08<00:00, 20.9MB/s] \n",
      "Some weights of the model checkpoint at TurkuNLP/bert-large-finnish-cased-v1 were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('Finnish-NLP/roberta-large-finnish')\n",
    "# model = RobertaModel.from_pretrained('Finnish-NLP/roberta-large-finnish')\n",
    "model_roberta = AutoModel.from_pretrained('Finnish-NLP/roberta-large-finnish')\n",
    "model_turku = AutoModel.from_pretrained(\"TurkuNLP/bert-large-finnish-cased-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.9925, -0.2804,  0.0515,  ...,  0.9504, -0.0999,  0.6405],\n",
      "         [ 1.7736,  0.1815, -0.8647,  ...,  0.8231,  0.2149,  0.7865],\n",
      "         [ 0.2692, -0.4999,  0.3979,  ...,  0.3658,  0.0418,  0.9323],\n",
      "         ...,\n",
      "         [ 0.5091,  0.3476, -0.2135,  ...,  0.5232,  0.2879, -0.9866],\n",
      "         [ 1.8058,  0.2573,  0.4596,  ...,  0.0110,  0.3241, -1.6292],\n",
      "         [ 0.7662, -0.6481,  0.1958,  ..., -0.0296, -0.3188,  1.5189]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.2203, -0.5763, -0.2142,  ...,  0.2957,  0.2482, -0.2921]],\n",
      "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "text = lappi_data.iloc[2432]\n",
    "tokenized_input = tokenizer(text, return_tensors='pt')\n",
    "token_encodings = model(**tokenized_input)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'input_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/nicklas/Projects/VaaliPerttu/data/browse_data.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nicklas/Projects/VaaliPerttu/data/browse_data.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Average pool the outputs into a single feature vector\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/nicklas/Projects/VaaliPerttu/data/browse_data.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(token_encodings[\u001b[39m'\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mshape) \u001b[39m# B, T\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nicklas/Projects/VaaliPerttu/data/browse_data.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(token_encodings[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape) \u001b[39m# B, T, D\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nicklas/Projects/VaaliPerttu/data/browse_data.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m encoded\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/generic.py:220\u001b[0m, in \u001b[0;36mModelOutput.__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(k, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    219\u001b[0m     inner_dict \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m (k, v) \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m--> 220\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_dict[k]\n\u001b[1;32m    221\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_tuple()[k]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'input_ids'"
     ]
    }
   ],
   "source": [
    "# Average pool the outputs into a single feature vector\n",
    "print(token_encodings['input_ids'].shape) # B, T\n",
    "print(token_encodings[0].shape) # B, T, D\n",
    "\n",
    "encoded\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaaliperttu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8aea22ac87b4d7775a71809f35a847f66f81cf5bafffb9ad80f891cde983deb6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
