model: 'end2end_mlp'

### Trainig
# epochs: 200
epochs: 200
epochs: 5000 # number of epochs
lr_start: 1e-6
lr_end: 1e-3
w_decay: 0.0005
w_decay_adj: 0.0
# patience: 10
patience: 3

### Architecture
hidden: 64
dropout: 0.5
nlayers: 2

# non_linearity: 'elu'
# mlp_act: 'relu'
# normalization: 'sym'
mlp_n_layers: 2
mlp_h: 50
mlp_epochs: 100
# gen_mode: 2
gen_mode: 1
# gen_mode: 0
sparse: 0
noise: 'mask'
# loss: 'mse'
loss: 'bce'
  
### GAT PARAMS
nheads: 1
concat_multihead: False

weight_decay: 0.01
  
# Data IO
# Save or load bert encodings.
slaps_save_dir: "slaps"

load_saved_data: True
save_data: False
# load_saved_data: False
# save_data: True
 
save_adjacency: True