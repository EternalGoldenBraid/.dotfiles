# Slaps 
epochs: 200
epochs_adj: 5000 # number of epochs
epoch_d: 10 # epochs_adj / epoch2 of the epochs will be used for training GNN_DAE
epochs_adj_warmup: 50
lr: 0.001
lr_adj: 0.01
w_decay: 0.0005
w_decay_adj: 0.0
# hidden: 512
hidden: 256
# hidden: 1024
hidden_adj: 32
dropout1: 0.5
dropout2: 0.5
dropout_adj1: 0.25
dropout_adj2: 0.25
dataset: 'cora'
nlayers: 2
nlayers_adj: 2
# patience: 10
patience: 3
ntrials: 1
k: 20
# k: 200
half_val_as_train: 0
ratio: 20
lambda_: 0.1
nr: 5
knn_metric: 'cosine'
# model: 'end2end'
model: 'end2end_mlp'
classifier: gat
# classifier: gcn

i: 6
non_linearity: 'elu'
mlp_act: 'relu'
normalization: 'sym'
mlp_n_layers: 2
mlp_h: 50
mlp_epochs: 100
# gen_mode: 2
gen_mode: 1
# gen_mode: 0
sparse: 0
noise: 'mask'
# loss: 'mse'
loss: 'bce'
  
### GAT PARAMS
nheads: 1
concat_multihead: False

# Bert # TODO This encoder description should be unassociated with the SLAPS model.
# model_id: "TurkuNLP/bert-base-finnish-cased-v1"
model_id: "TurkuNLP/bert-large-finnish-cased-v1"
max_length: 256     # Max token length
weight_decay: 0.01
  
# Data IO
# Save or load bert encodings.
slaps_save_dir: "slaps"

load_saved_data: True
save_data: False
# load_saved_data: False
# save_data: True
 
save_adjacency: True

# cuda_device: 1
